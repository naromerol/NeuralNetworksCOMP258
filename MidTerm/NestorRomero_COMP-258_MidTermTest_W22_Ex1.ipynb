{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635c4ae1",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS - COMP258\n",
    "## MIDTERM EXAM - EXERCISE 1\n",
    "## Nestor Romero - 301133331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bfef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba34982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERAL DATASET INFORMATION\n",
      "           variance     skewness     curtosis      entropy        class\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
      "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
      "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
      "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
      "max       6.824800    12.951600    17.927400     2.449500     1.000000 \n",
      "\n",
      "DATA SAMPLE\n",
      "    variance  skewness  curtosis  entropy  class\n",
      "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
      "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
      "2   3.86600   -2.6383    1.9242  0.10645      0\n",
      "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
      "4   0.32924   -4.4552    4.5718 -0.98880      0 \n",
      "\n",
      "CLASS VALUE COUNTS\n",
      " 0    762\n",
      "1    610\n",
      "Name: class, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## 1. LOAD DATASET FILE INTO DATA FRAME\n",
    "\n",
    "bank_notes_df = pd.read_csv('banknote_authentication.csv', names=['variance','skewness','curtosis','entropy', 'class'])\n",
    "print('GENERAL DATASET INFORMATION\\n', bank_notes_df.describe(),'\\n')\n",
    "print('DATA SAMPLE\\n', bank_notes_df.head(), '\\n')\n",
    "print('CLASS VALUE COUNTS\\n', bank_notes_df['class'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e1ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create random weights to initialize a layer\n",
    "def create_weights(num_units, num_inputs):\n",
    "    '''\n",
    "    Create a matrix of random values with shape (num_units, num_inputs)\n",
    "    num_units = Number of neurons in layer\n",
    "    num_inputs = Number of inputs from previous layer\n",
    "    '''\n",
    "    weights = 2* np.array(np.random.rand(num_units, num_inputs)) - 1\n",
    "    return weights\n",
    "\n",
    "# sigmoid function\n",
    "sigmoid = lambda x: 1/(1 + np.exp(-x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4964bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to execute final feed forward step with the trained network\n",
    "def feed_forward(whl, wol, inputs, outputs):\n",
    "    '''\n",
    "    This function calculates only the feed forward step for the network\n",
    "    It is used to calculate the final results of the network\n",
    "    whl = weights hidden layer\n",
    "    wol = weights output layer\n",
    "    '''\n",
    "    num_records = inputs.shape[0]\n",
    "    results = a = np.zeros(outputs.shape)\n",
    "    \n",
    "    for i in range(0, num_records):\n",
    "        \n",
    "        #for each row of values and results\n",
    "        x = inputs[i, :].T;    # current set of values\n",
    "        d = outputs[i];        # current set of results\n",
    "        \n",
    "        # FEEDFORWARD SECTION\n",
    "        # HIDDEN LAYER\n",
    "        # Calculate weighted sum and output\n",
    "        v1 = np.dot(whl,x);\n",
    "        y1 = sigmoid(v1);\n",
    "        \n",
    "        # OUTPUT LAYER\n",
    "        # Calculate weighted sum and output\n",
    "        v = np.dot(wol,y1);\n",
    "        y = sigmoid(v);\n",
    "        \n",
    "        #create results\n",
    "#         print(f'd = {d} y = {y}')\n",
    "        results[i] = y\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865fd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to execute backpropagation algorithm\n",
    "def back_propagation(whl, wol, inputs, outputs):\n",
    "    '''\n",
    "    This function calculates the feed forward and back propagation steps for the network\n",
    "    whl = weights hidden layer\n",
    "    wol = weights output layer\n",
    "    '''\n",
    "    # learning rate\n",
    "    alpha = 0.9;\n",
    "    \n",
    "    ### size variables to avoid hardcoding\n",
    "    num_records = inputs.shape[0]\n",
    "    size_input = inputs.shape[1]\n",
    "    size_output = wol.shape[0]\n",
    "    units_hidden = whl.shape[0]\n",
    "    units_output = wol.shape[0]\n",
    "    ###\n",
    "    \n",
    "    for i in range(0,num_records):\n",
    "        \n",
    "#         print(f'\\n\\nCURRENT ROW: {i}')\n",
    "        \n",
    "        #for each row of values and results\n",
    "        x = inputs[i, :].T;    # current set of values\n",
    "        d = outputs[i];        # current set of results\n",
    "        \n",
    "        # FEEDFORWARD SECTION\n",
    "        # HIDDEN LAYER\n",
    "        # Calculate weighted sum and output\n",
    "        v1 = np.dot(whl,x);\n",
    "        y1 = sigmoid(v1);\n",
    "\n",
    "        \n",
    "        # OUTPUT LAYER\n",
    "        # Calculate weighted sum and output\n",
    "        v = np.dot(wol,y1);\n",
    "        y = sigmoid(v);\n",
    "        \n",
    "        # CALCULATE ERROR AND DELTA\n",
    "        error = d - y;\n",
    "        delta = y * (1 - y) * error; # sigmoid prime!!!\n",
    "        \n",
    "        #\n",
    "        # BACKPROPAGATION SECTION\n",
    "        e1 = np.dot(wol.T, delta);\n",
    "        delta1 = y1 * (1 - y1) * e1;  \n",
    "        \n",
    "        # Adjust the weights according to the learning rule\n",
    "        # HIDDEN LAYER\n",
    "        delta1.shape=(units_hidden,1)   # column vector of deltas for the hidden layer\n",
    "        x.shape=(1,size_input)          # row vector of the current input\n",
    "        \n",
    "        dwhl = alpha * np.dot(delta1,x);\n",
    "        whl = whl + dwhl;\n",
    "        \n",
    "        # OUTPUT LAYER\n",
    "        delta.shape = (size_output,1)\n",
    "        y1.shape = (1, units_hidden)\n",
    "        \n",
    "        dwol = alpha*np.dot(delta,y1);\n",
    "        wol = wol + dwol;\n",
    "        \n",
    "    return whl, wol;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546b3b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.8237  ,   2.8597  ,   0.19678 ,   0.57196 ],\n",
       "       [  5.681   ,   7.795   ,  -2.6848  ,  -0.92544 ],\n",
       "       [ -0.4294  ,  -0.14693 ,   0.044265,  -0.15605 ],\n",
       "       ...,\n",
       "       [ -1.7263  ,  -6.0237  ,   5.2419  ,   0.29524 ],\n",
       "       [ -4.244   , -13.0634  ,  17.1116  ,  -2.8017  ],\n",
       "       [ -1.5768  ,  10.843   ,   2.5462  ,  -2.9362  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## 2. EXTRACT INPUT MATRIX AND OUTPUT COLUMN\n",
    "\n",
    "X = bank_notes_df.iloc[:,0:4].to_numpy() #Input values (n,4)\n",
    "y = bank_notes_df['class'].to_numpy()   #Output values (n)\n",
    "\n",
    "######## 3. SPLIT DATASET INTO TRAIN AND TEST\n",
    "# (70%-30% split) random_state used for replicable results\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=301133331)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43439fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\tINITIALIZE NETWORK WEIGHTS\n",
      "\tHidden Layer Weights - W1\n",
      "[[ 0.18332064 -0.75068694 -0.95455357  0.94320008]\n",
      " [ 0.24668493  0.37144921 -0.72560339 -0.90532626]\n",
      " [ 0.40960049  0.58089953  0.59263356  0.26810477]\n",
      " [-0.94909102  0.45420361 -0.61628618 -0.64252646]\n",
      " [-0.55559508 -0.68170695  0.51295861 -0.55816557]\n",
      " [ 0.94047852  0.13453754 -0.60079859  0.01735042]]\n",
      "\n",
      "\tOutput Layer Weights - W2\n",
      "[[ 0.17056033  0.19754935 -0.57823532  0.38417356  0.14968244 -0.89191795]]\n",
      "\n",
      "###\tNETWORK ARCHITECTURE\n",
      "Weights Hidden Layer Shape (W1) (6, 4)\n",
      "Weights Output Layer Shape (W2) (1, 6)\n",
      "\n",
      "###\tTRAINING NETWORK - BACK-PROPAGATION\n",
      "Train Inputs Shape (960, 4)\n",
      "Train Outputs Shape (960,)\n"
     ]
    }
   ],
   "source": [
    "# MAIN PROGRAM EXECUTION\n",
    "\n",
    "######## 4. INITIALIZE WEIGHTS\n",
    "\n",
    "# Create initial random weights for all layers\n",
    "W1 = create_weights(6,4) # Hidden layer 6 units and 4 inputs\n",
    "W2 = create_weights(1,6) # Output layer 1 unit 6 inputs\n",
    "\n",
    "print('###\\tINITIALIZE NETWORK WEIGHTS')\n",
    "print('\\tHidden Layer Weights - W1')\n",
    "print(W1)\n",
    "print()\n",
    "print('\\tOutput Layer Weights - W2')\n",
    "print(W2)\n",
    "\n",
    "print('\\n###\\tNETWORK ARCHITECTURE')\n",
    "print(f'Weights Hidden Layer Shape (W1) {W1.shape}')\n",
    "print(f'Weights Output Layer Shape (W2) {W2.shape}')\n",
    "\n",
    "print()\n",
    "print('###\\tTRAINING NETWORK - BACK-PROPAGATION')\n",
    "print(f'Train Inputs Shape {X_train.shape}')\n",
    "print(f'Train Outputs Shape {y_train.shape}')\n",
    "# Use back propagation to obtain NN weights\n",
    "W1, W2 = back_propagation(W1, W2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb73fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###\tTESTING DATA\n",
      "Test Inputs Shape (412, 4)\n",
      "Test Outputs Shape (412,)\n",
      "\n",
      "###\tFORMATTED SAMPLE RESULTS (10)\n",
      "x = [ 0.7057 -5.4981  8.3368 -2.8715],\ty = 0,\tpredicted_value = 0.06405193807190121,\ty_output = 0\n",
      "\n",
      "x = [ 0.33111  4.5731   2.057   -0.18967],\ty = 0,\tpredicted_value = 0.025550927161098053,\ty_output = 0\n",
      "\n",
      "x = [-0.27802  8.1881  -3.1338  -2.5276 ],\ty = 0,\tpredicted_value = 0.06297311215956405,\ty_output = 0\n",
      "\n",
      "x = [-2.2214  -0.23798  0.56008  0.05602],\ty = 1,\tpredicted_value = 0.9969569112680016,\ty_output = 1\n",
      "\n",
      "x = [ 1.9476 -4.7738  8.527  -1.8668],\ty = 0,\tpredicted_value = 0.02238962382584315,\ty_output = 0\n",
      "\n",
      "x = [ 5.6084 10.3009 -4.8003 -4.3534],\ty = 0,\tpredicted_value = 0.0367653800055792,\ty_output = 0\n",
      "\n",
      "x = [-2.121   -0.05588  1.949    1.353  ],\ty = 1,\tpredicted_value = 0.9799807590065568,\ty_output = 1\n",
      "\n",
      "x = [-3.2778  1.8023  0.1805 -2.3931],\ty = 1,\tpredicted_value = 0.9948376163715977,\ty_output = 1\n",
      "\n",
      "x = [ 0.89512  4.7738  -4.8431  -5.5909 ],\ty = 1,\tpredicted_value = 0.6077699601056378,\ty_output = 1\n",
      "\n",
      "x = [-1.7279  -6.841    8.9494   0.68058],\ty = 1,\tpredicted_value = 0.9679759636789343,\ty_output = 1\n",
      "\n",
      "\n",
      "### ACCURACY SCORE: 0.9733009708737864\n"
     ]
    }
   ],
   "source": [
    "print('\\n###\\tTESTING DATA')\n",
    "print(f'Test Inputs Shape {X_test.shape}')\n",
    "print(f'Test Outputs Shape {y_test.shape}')\n",
    "\n",
    "######## 5. CALCULATE OUTPUT OF THE NETWORK WITH A SAMPLE\n",
    "\n",
    "# Calculate results for test values with the weights obtained from back_propagation\n",
    "y_predicted = feed_forward(W1, W2, X_test, y_test)\n",
    "\n",
    "# transform result into an integer for comparison and accuracy calculation\n",
    "y_output = [ 1 if y > 0.5 else 0 for y in y_predicted ]\n",
    "\n",
    "sample_size = 10\n",
    "print(f'\\n###\\tFORMATTED SAMPLE RESULTS ({sample_size})')\n",
    "\n",
    "# Print 5 samples of data results vs predicted\n",
    "for i in range(0, sample_size):\n",
    "    print(f'x = {X_test[i]},\\ty = {y_test[i]},\\tpredicted_value = {y_predicted[i]},\\ty_output = {y_output[i]}\\n')\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_output)\n",
    "print(f'\\n### ACCURACY SCORE: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:comp258]",
   "language": "python",
   "name": "conda-env-comp258-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
