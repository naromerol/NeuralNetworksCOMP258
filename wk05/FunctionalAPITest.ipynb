{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see paper) connects all or part of the inputs directly to the output layer.\n",
    "Letâ€™s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 872us/step - loss: 1.3035 - val_loss: 0.7101\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.6619 - val_loss: 0.6456\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 531us/step - loss: 0.6156 - val_loss: 0.6133\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 526us/step - loss: 0.5873 - val_loss: 0.5928\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.5664 - val_loss: 0.5708\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.5470 - val_loss: 0.5567\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 533us/step - loss: 0.5324 - val_loss: 0.5430\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.5193 - val_loss: 0.5318\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.5088 - val_loss: 0.5219\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 520us/step - loss: 0.4994 - val_loss: 0.5134\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.4909 - val_loss: 0.5059\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.4837 - val_loss: 0.4984\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.4771 - val_loss: 0.4913\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.4713 - val_loss: 0.4864\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 523us/step - loss: 0.4658 - val_loss: 0.4823\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 521us/step - loss: 0.4612 - val_loss: 0.4769\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 518us/step - loss: 0.4566 - val_loss: 0.4740\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 513us/step - loss: 0.4529 - val_loss: 0.4699\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 515us/step - loss: 0.4493 - val_loss: 0.4653\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.4457 - val_loss: 0.4636\n",
      "162/162 [==============================] - 0s 351us/step - loss: 0.4568\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to send different subsets of input features through the wide or deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 0s - loss: 12.1456WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0000s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 771us/step - loss: 1.8248 - val_loss: 0.7923\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 567us/step - loss: 0.7055 - val_loss: 0.6450\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.6258 - val_loss: 0.6057\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.5910 - val_loss: 0.5840\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.5690 - val_loss: 0.5665\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.5508 - val_loss: 0.5542\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.5373 - val_loss: 0.5430\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.5256 - val_loss: 0.5343\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.5168 - val_loss: 0.5270\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 543us/step - loss: 0.5093 - val_loss: 0.5214\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 532us/step - loss: 0.5027 - val_loss: 0.5163\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.4972 - val_loss: 0.5128\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.4925 - val_loss: 0.5091\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.4887 - val_loss: 0.5048\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 538us/step - loss: 0.4845 - val_loss: 0.5027\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.4818 - val_loss: 0.4996\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 535us/step - loss: 0.4782 - val_loss: 0.4978\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.4759 - val_loss: 0.4953\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.4732 - val_loss: 0.4923\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 536us/step - loss: 0.4708 - val_loss: 0.4910\n",
      "162/162 [==============================] - 0s 364us/step - loss: 0.4846\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 2.1377 - main_output_loss: 1.9300 - aux_output_loss: 4.0068 - val_loss: 1.0631 - val_main_output_loss: 0.8288 - val_aux_output_loss: 3.1725\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.9125 - main_output_loss: 0.7249 - aux_output_loss: 2.6008 - val_loss: 0.8148 - val_main_output_loss: 0.6557 - val_aux_output_loss: 2.2465\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 607us/step - loss: 0.7656 - main_output_loss: 0.6357 - aux_output_loss: 1.9353 - val_loss: 0.7374 - val_main_output_loss: 0.6142 - val_aux_output_loss: 1.8463\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.7043 - main_output_loss: 0.5994 - aux_output_loss: 1.6482 - val_loss: 0.6974 - val_main_output_loss: 0.5923 - val_aux_output_loss: 1.6432\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.6687 - main_output_loss: 0.5769 - aux_output_loss: 1.4948 - val_loss: 0.6679 - val_main_output_loss: 0.5734 - val_aux_output_loss: 1.5184\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 632us/step - loss: 0.6423 - main_output_loss: 0.5582 - aux_output_loss: 1.3996 - val_loss: 0.6461 - val_main_output_loss: 0.5585 - val_aux_output_loss: 1.4349\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 615us/step - loss: 0.6221 - main_output_loss: 0.5429 - aux_output_loss: 1.3343 - val_loss: 0.6277 - val_main_output_loss: 0.5473 - val_aux_output_loss: 1.3516\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.6051 - main_output_loss: 0.5304 - aux_output_loss: 1.2780 - val_loss: 0.6127 - val_main_output_loss: 0.5371 - val_aux_output_loss: 1.2929\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 614us/step - loss: 0.5916 - main_output_loss: 0.5207 - aux_output_loss: 1.2301 - val_loss: 0.6003 - val_main_output_loss: 0.5287 - val_aux_output_loss: 1.2442\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.5804 - main_output_loss: 0.5126 - aux_output_loss: 1.1915 - val_loss: 0.5902 - val_main_output_loss: 0.5219 - val_aux_output_loss: 1.2044\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.5706 - main_output_loss: 0.5053 - aux_output_loss: 1.1584 - val_loss: 0.5816 - val_main_output_loss: 0.5165 - val_aux_output_loss: 1.1674\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 618us/step - loss: 0.5624 - main_output_loss: 0.4996 - aux_output_loss: 1.1278 - val_loss: 0.5748 - val_main_output_loss: 0.5128 - val_aux_output_loss: 1.1329\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.5552 - main_output_loss: 0.4945 - aux_output_loss: 1.1011 - val_loss: 0.5682 - val_main_output_loss: 0.5082 - val_aux_output_loss: 1.1079\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.5490 - main_output_loss: 0.4902 - aux_output_loss: 1.0784 - val_loss: 0.5618 - val_main_output_loss: 0.5039 - val_aux_output_loss: 1.0834\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.5430 - main_output_loss: 0.4860 - aux_output_loss: 1.0558 - val_loss: 0.5579 - val_main_output_loss: 0.5019 - val_aux_output_loss: 1.0613\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 625us/step - loss: 0.5384 - main_output_loss: 0.4832 - aux_output_loss: 1.0347 - val_loss: 0.5527 - val_main_output_loss: 0.4983 - val_aux_output_loss: 1.0422\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 656us/step - loss: 0.5334 - main_output_loss: 0.4798 - aux_output_loss: 1.0162 - val_loss: 0.5493 - val_main_output_loss: 0.4966 - val_aux_output_loss: 1.0235\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 651us/step - loss: 0.5294 - main_output_loss: 0.4772 - aux_output_loss: 0.9991 - val_loss: 0.5454 - val_main_output_loss: 0.4942 - val_aux_output_loss: 1.0061\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.5256 - main_output_loss: 0.4748 - aux_output_loss: 0.9823 - val_loss: 0.5413 - val_main_output_loss: 0.4914 - val_aux_output_loss: 0.9909\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 661us/step - loss: 0.5218 - main_output_loss: 0.4724 - aux_output_loss: 0.9672 - val_loss: 0.5388 - val_main_output_loss: 0.4903 - val_aux_output_loss: 0.9755\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 454us/step - loss: 0.5287 - main_output_loss: 0.4825 - aux_output_loss: 0.9444\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
